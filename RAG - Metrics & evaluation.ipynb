{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"197p2UKDZyw-5usXh98Dmvleo8hk51vl8","authorship_tag":"ABX9TyMyDygtfl9g0vros9LuJnq4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8PRCRz7qaSRq","executionInfo":{"status":"ok","timestamp":1703482093973,"user_tz":-330,"elapsed":44157,"user":{"displayName":"Vinod Karmenghe","userId":"03219374517341570992"}},"outputId":"65f4bfbb-b884-4f28-a0e8-30673c66f3d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m943.5/943.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m583.4/583.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.5/221.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.0/82.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.8/81.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for deeplake (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q llama-index==0.9.14.post3 deeplake==3.8.12 openai==1.3.8 cohere==4.37"]},{"cell_type":"code","source":["!pip install -q python-dotenv"],"metadata":{"id":"59NOpBFrcuNw","executionInfo":{"status":"ok","timestamp":1703482211487,"user_tz":-330,"elapsed":10418,"user":{"displayName":"Vinod Karmenghe","userId":"03219374517341570992"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from dotenv import load_dotenv\n","load_dotenv('drive/MyDrive/.env')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L3ixy_oec6oj","executionInfo":{"status":"ok","timestamp":1703482295181,"user_tz":-330,"elapsed":703,"user":{"displayName":"Vinod Karmenghe","userId":"03219374517341570992"}},"outputId":"f638d1c3-83f6-4ec6-9150-a57f8f852953"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["# **Faithfulness(Answer to Context)**"],"metadata":{"id":"SuixiozjccrU"}},{"cell_type":"code","source":["from llama_index import ServiceContext\n","from llama_index.llms import OpenAI\n","\n","# build service context\n","llm = OpenAI(model=\"gpt-4\", temperature=0.0)\n","service_context = ServiceContext.from_defaults(llm=llm)\n","\n","from llama_index.vector_stores import DeepLakeVectorStore\n","from llama_index.storage.storage_context import StorageContext\n","from llama_index import VectorStoreIndex\n","\n","vector_store = DeepLakeVectorStore(dataset_path=\"hub://vinodkarmenghe/LlamaIndex_paulgraham_essays\", overwrite=False)\n","storage_context = StorageContext.from_defaults(vector_store=vector_store)\n","\n","index = VectorStoreIndex.from_vector_store(\n","    vector_store, storage_context=storage_context\n",")\n","\n","from llama_index.evaluation import FaithfulnessEvaluator\n","\n","# define evaluator\n","evaluator = FaithfulnessEvaluator(service_context=service_context)\n","\n","# query index\n","query_engine = index.as_query_engine()\n","response = query_engine.query(\"What does Paul Graham do?\")\n","print(response)\n","\n","eval_result = evaluator.evaluate_response(response=response)\n","\n","print( \"> response:\", response )\n","\n","print( \"> evaluator result:\", eval_result.passing )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-RJazM0rcXWW","executionInfo":{"status":"ok","timestamp":1703482763373,"user_tz":-330,"elapsed":19704,"user":{"displayName":"Vinod Karmenghe","userId":"03219374517341570992"}},"outputId":"c7d8ec21-697f-41db-8856-f1c20825a769"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Deep Lake Dataset in hub://vinodkarmenghe/LlamaIndex_paulgraham_essays already exists, loading from the storage\n","Paul Graham gives talks and writes essays. He has given talks on topics such as how to start a startup and has used this as a way to share his insights and advice. He also has a trick of giving talks to help him write essays.\n","> response: Paul Graham gives talks and writes essays. He has given talks on topics such as how to start a startup and has used this as a way to share his insights and advice. He also has a trick of giving talks to help him write essays.\n","> evaluator result: True\n"]}]},{"cell_type":"markdown","source":["# Evaluating with Ragas\n","The evaluation process involves importing specific metrics from Ragas, such as faithfulness, answer relevancy, context precision, context recall, and harmfulness.\n","\n","When evaluating using Ragas, the following elements are essential:\n","\n","**Query Engine**: This is the primary component and acts as the core of the evaluation process, where its performance is assessed.\n","\n","**Metrics**: Ragas provides a range of metrics specifically designed to evaluate a nuanced assessment of the engine's capabilities.\n","\n","**Questions**: A curated set of questions is required, which are used to probe the engine's ability to retrieve and generate accurate responses."],"metadata":{"id":"0jsO8aAniWE9"}},{"cell_type":"code","source":["!pip install html2text==2020.1.16 ragas==0.0.22"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TgZlmDhPiOj2","executionInfo":{"status":"ok","timestamp":1703483719268,"user_tz":-330,"elapsed":14755,"user":{"displayName":"Vinod Karmenghe","userId":"03219374517341570992"}},"outputId":"0e7f9d49-dd0c-4a7d-8126-376da58196e8"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting html2text==2020.1.16\n","  Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\n","Collecting ragas==0.0.22\n","  Downloading ragas-0.0.22-py3-none-any.whl (52 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ragas==0.0.22) (1.23.5)\n","Collecting datasets (from ragas==0.0.22)\n","  Downloading datasets-2.16.0-py3-none-any.whl (507 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from ragas==0.0.22) (0.5.2)\n","Collecting langchain (from ragas==0.0.22)\n","  Downloading langchain-0.0.352-py3-none-any.whl (794 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m794.4/794.4 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: openai>1 in /usr/local/lib/python3.10/dist-packages (from ragas==0.0.22) (1.3.8)\n","Collecting pysbd>=0.3.4 (from ragas==0.0.22)\n","  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ragas==0.0.22) (1.5.8)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas==0.0.22) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>1->ragas==0.0.22) (1.7.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas==0.0.22) (0.26.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas==0.0.22) (1.10.13)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas==0.0.22) (1.3.0)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas==0.0.22) (4.66.1)\n","Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas==0.0.22) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.0.22) (3.13.1)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.0.22) (10.0.1)\n","Collecting pyarrow-hotfix (from datasets->ragas==0.0.22)\n","  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.0.22) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.0.22) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.0.22) (2.31.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.0.22) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.0.22) (0.70.15)\n","Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.0.22) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.0.22) (3.9.1)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.0.22) (0.19.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.0.22) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.0.22) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas==0.0.22) (2.0.23)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas==0.0.22) (4.0.3)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas==0.0.22) (0.6.3)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain->ragas==0.0.22)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Collecting langchain-community<0.1,>=0.0.2 (from langchain->ragas==0.0.22)\n","  Downloading langchain_community-0.0.6-py3-none-any.whl (1.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain-core<0.2,>=0.1 (from langchain->ragas==0.0.22)\n","  Downloading langchain_core-0.1.3-py3-none-any.whl (192 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.4/192.4 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langsmith<0.1.0,>=0.0.70 (from langchain->ragas==0.0.22)\n","  Downloading langsmith-0.0.75-py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas==0.0.22) (8.2.3)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->ragas==0.0.22) (2023.6.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas==0.0.22) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas==0.0.22) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas==0.0.22) (1.9.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas==0.0.22) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas==0.0.22) (1.3.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>1->ragas==0.0.22) (3.6)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>1->ragas==0.0.22) (1.2.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain->ragas==0.0.22) (3.20.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain->ragas==0.0.22) (0.9.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>1->ragas==0.0.22) (2023.11.17)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>1->ragas==0.0.22) (1.0.2)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas==0.0.22) (0.14.0)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain->ragas==0.0.22)\n","  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->ragas==0.0.22) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->ragas==0.0.22) (2.0.7)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->ragas==0.0.22) (3.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas==0.0.22) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas==0.0.22) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->ragas==0.0.22) (1.16.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain->ragas==0.0.22) (1.0.0)\n","Installing collected packages: pysbd, pyarrow-hotfix, jsonpointer, html2text, langsmith, jsonpatch, langchain-core, langchain-community, datasets, langchain, ragas\n","Successfully installed datasets-2.16.0 html2text-2020.1.16 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.352 langchain-community-0.0.6 langchain-core-0.1.3 langsmith-0.0.75 pyarrow-hotfix-0.6 pysbd-0.3.4 ragas-0.0.22\n"]}]},{"cell_type":"code","source":["from llama_index.readers.web import SimpleWebPageReader\n","from llama_index import VectorStoreIndex, ServiceContext\n","\n","documents = SimpleWebPageReader(html_to_text=True).load_data( [\"https://en.wikipedia.org/wiki/New_York_City\"] )\n","\n","vector_index = VectorStoreIndex.from_documents(\n","    documents, service_context=ServiceContext.from_defaults(chunk_size=512)\n",")\n","\n","query_engine = vector_index.as_query_engine()\n","\n","response_vector = query_engine.query(\"How did New York City get its name?\")\n","\n","print(response_vector)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xHKQpERtiPpe","executionInfo":{"status":"ok","timestamp":1703483763708,"user_tz":-330,"elapsed":44461,"user":{"displayName":"Vinod Karmenghe","userId":"03219374517341570992"}},"outputId":"2151c10b-02df-49d1-8f4d-3c52922a4c88"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["New York City got its name in honor of the Duke of York, who later became King James II of England. The Duke of York was appointed as the proprietor of the former territory of New Netherland, including the city of New Amsterdam, when England seized it from Dutch control.\n"]}]},{"cell_type":"code","source":["eval_questions = [\n","    \"What is the population of New York City as of 2020?\",\n","    \"Which borough of New York City has the highest population?\",\n","    \"What is the economic significance of New York City?\",\n","    \"How did New York City get its name?\",\n","    \"What is the significance of the Statue of Liberty in New York City?\",\n","]\n","\n","eval_answers = [\n","    \"8,804,000\",  # incorrect answer\n","    \"Queens\",  # incorrect answer\n","    \"New York City's economic significance is vast, as it serves as the global financial capital, housing Wall Street and major financial institutions. Its diverse economy spans technology, media, healthcare, education, and more, making it resilient to economic fluctuations. NYC is a hub for international business, attracting global companies, and boasts a large, skilled labor force. Its real estate market, tourism, cultural industries, and educational institutions further fuel its economic prowess. The city's transportation network and global influence amplify its impact on the world stage, solidifying its status as a vital economic player and cultural epicenter.\",\n","    \"New York City got its name when it came under British control in 1664. King Charles II of England granted the lands to his brother, the Duke of York, who named the city New York in his own honor.\",\n","    \"The Statue of Liberty in New York City holds great significance as a symbol of the United States and its ideals of liberty and peace. It greeted millions of immigrants who arrived in the U.S. by ship in the late 19th and early 20th centuries, representing hope and freedom for those seeking a better life. It has since become an iconic landmark and a global symbol of cultural diversity and freedom.\",\n","]\n","\n","eval_answers = [[a] for a in eval_answers]"],"metadata":{"id":"lgphu3gXiuOr","executionInfo":{"status":"ok","timestamp":1703483763709,"user_tz":-330,"elapsed":62,"user":{"displayName":"Vinod Karmenghe","userId":"03219374517341570992"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["from ragas.metrics import (\n","    faithfulness,\n","    answer_relevancy,\n","    context_precision,\n","    context_recall,\n",")\n","from ragas.metrics.critique import harmfulness\n","\n","metrics = [\n","    faithfulness,\n","    answer_relevancy,\n","    context_precision,\n","    context_recall,\n","    harmfulness,\n","]"],"metadata":{"id":"-Zk_l4MMiy9x","executionInfo":{"status":"ok","timestamp":1703483767010,"user_tz":-330,"elapsed":3358,"user":{"displayName":"Vinod Karmenghe","userId":"03219374517341570992"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["from ragas.llama_index import evaluate\n","\n","result = evaluate(query_engine, metrics, eval_questions, eval_answers)\n","\n","# print the final scores\n","print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Neiy_2nui4Yj","executionInfo":{"status":"ok","timestamp":1703483808253,"user_tz":-330,"elapsed":33951,"user":{"displayName":"Vinod Karmenghe","userId":"03219374517341570992"}},"outputId":"3ad71097-ea17-446d-a131-68c52438744a"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["evaluating with [faithfulness]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:14<00:00, 14.86s/it]\n"]},{"output_type":"stream","name":"stdout","text":["evaluating with [answer_relevancy]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:03<00:00,  3.84s/it]\n"]},{"output_type":"stream","name":"stdout","text":["evaluating with [context_precision]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n"]},{"output_type":"stream","name":"stdout","text":["evaluating with [context_recall]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:05<00:00,  5.47s/it]\n"]},{"output_type":"stream","name":"stdout","text":["evaluating with [harmfulness]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n"]},{"output_type":"stream","name":"stdout","text":["{'faithfulness': 0.8000, 'answer_relevancy': 0.7469, 'context_precision': 0.6000, 'context_recall': 0.9000, 'harmfulness': 0.0000}\n"]}]},{"cell_type":"markdown","source":["# The Custom RAG Pipeline Evaluation"],"metadata":{"id":"DRl9IRYljp4G"}},{"cell_type":"code","source":["!wget 'https://raw.githubusercontent.com/idontcalculate/data-repo/main/venus_transmission.txt'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hKRs-6_2jnbZ","executionInfo":{"status":"ok","timestamp":1703483971719,"user_tz":-330,"elapsed":625,"user":{"displayName":"Vinod Karmenghe","userId":"03219374517341570992"}},"outputId":"8d6562d4-4a60-436d-9c53-5016b4f58917"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-12-25 05:59:30--  https://raw.githubusercontent.com/idontcalculate/data-repo/main/venus_transmission.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 19241 (19K) [text/plain]\n","Saving to: ‘venus_transmission.txt’\n","\n","\rvenus_transmission.   0%[                    ]       0  --.-KB/s               \rvenus_transmission. 100%[===================>]  18.79K  --.-KB/s    in 0s      \n","\n","2023-12-25 05:59:30 (117 MB/s) - ‘venus_transmission.txt’ saved [19241/19241]\n","\n"]}]},{"cell_type":"code","source":["from llama_index import SimpleDirectoryReader\n","\n","reader = SimpleDirectoryReader(input_files=[\"/content/venus_transmission.txt\"])\n","\n","docs = reader.load_data()\n","print(f\"Loaded {len(docs)} docs\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2qExN0egjtEH","executionInfo":{"status":"ok","timestamp":1703484007558,"user_tz":-330,"elapsed":605,"user":{"displayName":"Vinod Karmenghe","userId":"03219374517341570992"}},"outputId":"02415429-eb91-4d53-9ca9-67c14135b320"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded 1 docs\n"]}]},{"cell_type":"code","source":["from llama_index.node_parser import SimpleNodeParser\n","from llama_index import VectorStoreIndex\n","\n","# Build index with a chunk_size of 512\n","node_parser = SimpleNodeParser.from_defaults(chunk_size=512)\n","nodes = node_parser.get_nodes_from_documents(docs)\n","vector_index = VectorStoreIndex(nodes)"],"metadata":{"id":"X04VqJJZj3K-","executionInfo":{"status":"ok","timestamp":1703484035449,"user_tz":-330,"elapsed":1726,"user":{"displayName":"Vinod Karmenghe","userId":"03219374517341570992"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["query_engine = vector_index.as_query_engine()\n","\n","response_vector = query_engine.query(\"What was The first beings to inhabit the planet?\")\n","print( response_vector.response )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q37qfaByj7Un","executionInfo":{"status":"ok","timestamp":1703484050801,"user_tz":-330,"elapsed":2602,"user":{"displayName":"Vinod Karmenghe","userId":"03219374517341570992"}},"outputId":"aa2d760f-1bd7-4a03-f772-d6d740448d7e"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["The first beings to inhabit the planet were a dinoid and reptoid race from two different systems outside our solar system.\n"]}]},{"cell_type":"code","source":["response_vector.source_nodes[0].get_text()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"id":"amZclE4AkL-m","executionInfo":{"status":"ok","timestamp":1703484132391,"user_tz":-330,"elapsed":913,"user":{"displayName":"Vinod Karmenghe","userId":"03219374517341570992"}},"outputId":"fb335110-3247-426b-d27b-c02cc50c8be9"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"They had heard of this beautiful new planet. At this time, Earth had two moons to harmonize the weather conditions and control the tides of the large bodies of water.\\nThe first beings to inhabit the planet were a dinoid and reptoid race from two different systems outside our solar system. They were intelligent and walked on two legs like humans and were war-like considering themselves to be superior to all other life forms. In the past, the four races of humans had conflicts with them before they outgrew such behavior. They arrived on Earth to rob it of its minerals and valuable gems. Soon they had created a terrible war. They were joined by re-\\n1\\nenforcements from their home planets. One set up its base on one of the Earth's moons, the other on Earth. It was a terrible war with advanced nuclear and laser weapons like you see in your science fiction movies. It lasted very long. Most of the life forms lay in singed waste and the one moon was destroyed. No longer interested in Earth, they went back to their planets leaving their wounded behind, they had no use for them.\\nThe four races sent a few forces to see if they could help the wounded dinoids and reptilians and to see what they could do to repair the Earth. They soon found that due to the nuclear radiation it was too dangerous on Earth before it was cleared. Even they had to remain so as not to contaminate their own planets.\\nDue to the radiation, the survivors of the dinoids and reptoids mutated into the Dinosaurs and giant reptilians you know of in your history. The humans that were trapped there mutated into what you call Neanderthals.\\nThe Earth remained a devastated ruin, covered by a huge dark nuclear cloud and what vegetation was left was being devoured by the giant beings, also humans and animals by some. It was this way for hundreds of years before a giant comet crashed into one of the oceans and created another huge cloud. This created such darkness that the radiating heat of the Sun could not interact with Earth's gravitational field and an ice age was created. This destroyed the mutated life forms and gave the four races the chance to cleanse and heal the Earth with technology and their energy.\\nOnce again, they brought various forms of life to the Earth, creating again a paradise, except for extreme weather conditions and extreme tidal activities.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["# **generate_question_context_pairs**"],"metadata":{"id":"GJVsjH5Xk7ru"}},{"cell_type":"code","source":["from llama_index.llms import OpenAI\n","from llama_index.evaluation import generate_question_context_pairs\n","\n","# Define an LLM\n","llm = OpenAI(model=\"gpt-3.5-turbo\")\n","\n","qa_dataset = generate_question_context_pairs(\n","    nodes,\n","    llm=llm,\n","    num_questions_per_chunk=2\n",")\n","\n","queries = list(qa_dataset.queries.values())\n","print( queries[0:10] )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jcmBGk8Pk0V3","executionInfo":{"status":"ok","timestamp":1703484369169,"user_tz":-330,"elapsed":26545,"user":{"displayName":"Vinod Karmenghe","userId":"03219374517341570992"}},"outputId":"d8534c5e-9e39-4fae-841b-f599c7d1c27a"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:25<00:00,  1.98s/it]"]},{"output_type":"stream","name":"stdout","text":["['Explain the role of different alien races in the history of our solar system according to the information provided. How did these races contribute to the transformation process of Earth?', 'Discuss the advanced abilities and technology possessed by the beings described in the context. How did their understanding of creation and their eternal nature shape their approach to life and their responsibilities as protectors of all life on different planets?', 'Explain the concept of creativity as understood by the advanced races mentioned in the context. How did they use their creative energy and what were the responsibilities associated with it?', 'Describe the initial state of Earth before it became a planet and settled into an orbit around the Sun. How did the four races contribute to the development of life on Earth?', 'How did the arrival of the dinoid and reptoid races on Earth lead to a devastating war? Discuss the reasons behind their conflict with the four races of humans and the consequences of their actions on Earth.', 'Explain the impact of the giant comet crash on Earth, resulting in the creation of an ice age. Discuss how this event affected the mutated life forms, the opportunity it provided for the four races to cleanse and heal the Earth, and the challenges posed by extreme weather conditions and tidal activities in the newly restored paradise.', 'How did the survivors of the dinoids and reptoids mutate into the dinosaurs and giant reptilians we know of in history? Explain the role of radiation in this process.', 'Describe the events that led to the creation of an ice age on Earth. How did this ice age impact the mutated life forms and provide an opportunity for the four races to cleanse and heal the Earth?', 'Explain the purpose and significance of the hidden temples built by the inhabitants of the Earth in the context of the aggressive beings. How did these temples serve as doorways to other dimensions and why were they hidden for future times?', 'Discuss the actions taken by the colonies in response to the war declared by another race of humans. How did the colonies protect their knowledge and technology from falling into the hands of the dark forces? Additionally, explain the role of Lemuria and Atlantis in this process and why they were destroyed by their inhabitants.']\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["from llama_index.evaluation import RetrieverEvaluator\n","import pandas as pd\n","\n","retriever = vector_index.as_retriever(similarity_top_k=2)\n","\n","retriever_evaluator = RetrieverEvaluator.from_metric_names(\n","    [\"mrr\", \"hit_rate\"], retriever=retriever\n",")\n","\n","# Evaluate\n","eval_results = await retriever_evaluator.aevaluate_dataset(qa_dataset)\n","\n","def display_results(name, eval_results):\n","    \"\"\"Display results from evaluate.\"\"\"\n","\n","    metric_dicts = []\n","    for eval_result in eval_results:\n","        metric_dict = eval_result.metric_vals_dict\n","        metric_dicts.append(metric_dict)\n","\n","    full_df = pd.DataFrame(metric_dicts)\n","\n","    hit_rate = full_df[\"hit_rate\"].mean()\n","    mrr = full_df[\"mrr\"].mean()\n","\n","    metric_df = pd.DataFrame(\n","        {\"Retriever Name\": [name], \"Hit Rate\": [hit_rate], \"MRR\": [mrr]}\n","    )\n","\n","    return metric_df\n","\n","\n","display_results(\"OpenAI Embedding Retriever\", eval_results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"luUKRd79k-e0","executionInfo":{"status":"ok","timestamp":1703484492214,"user_tz":-330,"elapsed":3408,"user":{"displayName":"Vinod Karmenghe","userId":"03219374517341570992"}},"outputId":"33d13d7c-cb3b-4cf1-fa67-129a3ad2a88b"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               Retriever Name  Hit Rate       MRR\n","0  OpenAI Embedding Retriever  0.961538  0.846154"],"text/html":["\n","  <div id=\"df-9baea011-7607-40bf-88fe-ccf0d3d2d358\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Retriever Name</th>\n","      <th>Hit Rate</th>\n","      <th>MRR</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>OpenAI Embedding Retriever</td>\n","      <td>0.961538</td>\n","      <td>0.846154</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9baea011-7607-40bf-88fe-ccf0d3d2d358')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9baea011-7607-40bf-88fe-ccf0d3d2d358 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9baea011-7607-40bf-88fe-ccf0d3d2d358');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["# gpt-3.5-turbo\n","gpt35 = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n","service_context_gpt35 = ServiceContext.from_defaults(llm=gpt35)\n","\n","# gpt-4\n","gpt4 = OpenAI(temperature=0, model=\"gpt-4\")\n","service_context_gpt4 = ServiceContext.from_defaults(llm=gpt4)\n","\n","vector_index = VectorStoreIndex(nodes, service_context = service_context_gpt35)\n","query_engine = vector_index.as_query_engine()\n","\n","eval_query = queries[10]\n","response_vector = query_engine.query(eval_query)\n","\n","print( \"> eval_query: \", eval_query )\n","print( \"> response_vector:\", response_vector )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qdfMeaU0l4Ec","executionInfo":{"status":"ok","timestamp":1703484564679,"user_tz":-330,"elapsed":3688,"user":{"displayName":"Vinod Karmenghe","userId":"03219374517341570992"}},"outputId":"e7895486-4533-4bb9-ffc4-ed6a201609b1"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["> eval_query:  How did the colonies respond to the declaration of war by the dark forces, and what measures did they take to protect their knowledge and technology?\n","> response_vector: The colonies did not fight back against the dark forces when they declared war. Instead, they sent most of their people into hiding in order to rebuild the colonies later. They also destroyed everything to ensure that their knowledge and technology would not fall into the hands of the dark forces. Additionally, Lemuria and Atlantis were destroyed by their inhabitants to prevent the misuse of their knowledge and technology by the dark forces.\n"]}]},{"cell_type":"code","source":["# Now, we can establish the evaluator classes responsible for measuring each metric. We'll then use a sample response to determine if it meets the test criteria.\n","\n","# Copy\n","from llama_index.evaluation import RelevancyEvaluator\n","from llama_index.evaluation import FaithfulnessEvaluator\n","\n","relevancy_gpt4 = RelevancyEvaluator(service_context=service_context_gpt4)\n","faithfulness_gpt4 = FaithfulnessEvaluator(service_context=service_context_gpt4)\n","\n","# Compute faithfulness evaluation\n","\n","eval_result = faithfulness_gpt4.evaluate_response(response=response_vector)\n","# check passing parameter in eval_result if it passed the evaluation.\n","print( eval_result.passing )\n","\n","# Relevancy evaluation\n","eval_result = relevancy_gpt4.evaluate_response(\n","    query=eval_query, response=response_vector\n",")\n","# You can check passing parameter in eval_result if it passed the evaluation.\n","print( eval_result.passing )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T8swM0AfmILP","executionInfo":{"status":"ok","timestamp":1703484637917,"user_tz":-330,"elapsed":3072,"user":{"displayName":"Vinod Karmenghe","userId":"03219374517341570992"}},"outputId":"50509312-fa11-44a3-837e-91ccc15d9bcf"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","True\n"]}]},{"cell_type":"code","source":["#Batch Evaluator:\n","#BatchEvalRunner to compute multiple evaluations in batch wise manner.\n","\n","from llama_index.evaluation import BatchEvalRunner\n","\n","# Let's pick top 10 queries to do evaluation\n","batch_eval_queries = queries[:10]\n","\n","# Initiate BatchEvalRunner to compute FaithFulness and Relevancy Evaluation.\n","runner = BatchEvalRunner(\n","    {\"faithfulness\": faithfulness_gpt4, \"relevancy\": relevancy_gpt4},\n","    workers=8,\n",")\n","\n","# Compute evaluation\n","eval_results = await runner.aevaluate_queries(\n","    query_engine, queries=batch_eval_queries\n",")\n","\n","# get faithfulness score\n","faithfulness_score = sum(result.passing for result in eval_results['faithfulness']) / len(eval_results['faithfulness'])\n","# get relevancy score\n","relevancy_score = sum(result.passing for result in eval_results['faithfulness']) / len(eval_results['relevancy'])\n","\n","print( \"> faithfulness_score\", faithfulness_score )\n","print( \"> relevancy_score\", relevancy_score )\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FVBVZIJ1mWEV","executionInfo":{"status":"ok","timestamp":1703484705878,"user_tz":-330,"elapsed":11626,"user":{"displayName":"Vinod Karmenghe","userId":"03219374517341570992"}},"outputId":"894be3af-80b8-4ab9-f2e6-c24ead5ecd01"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["> faithfulness_score 1.0\n","> relevancy_score 1.0\n"]}]}]}